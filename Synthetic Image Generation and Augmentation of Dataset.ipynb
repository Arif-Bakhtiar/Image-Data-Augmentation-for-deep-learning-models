{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator , load_img, img_to_array, array_to_img\nfrom keras.datasets import mnist\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelBinarizer\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix, auc, roc_curve\nfrom tensorflow.keras.applications import InceptionResNetV2  # Use Inception-ResNetV2\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-18T22:13:10.312982Z","iopub.execute_input":"2023-09-18T22:13:10.316520Z","iopub.status.idle":"2023-09-18T22:13:19.947014Z","shell.execute_reply.started":"2023-09-18T22:13:10.316470Z","shell.execute_reply":"2023-09-18T22:13:19.946027Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"# Check GPU availability\nprint(tf.test.is_gpu_available())\nprint(tf.config.list_physical_devices('GPU'))","metadata":{"execution":{"iopub.status.busy":"2023-09-18T22:13:19.949004Z","iopub.execute_input":"2023-09-18T22:13:19.949648Z","iopub.status.idle":"2023-09-18T22:13:22.855301Z","shell.execute_reply.started":"2023-09-18T22:13:19.949611Z","shell.execute_reply":"2023-09-18T22:13:22.853996Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"True\n[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load the dataset and visualize images\nlabels = os.listdir(\"/kaggle/input/drowsiness-dataset/train\")\n","metadata":{"execution":{"iopub.status.busy":"2023-09-18T22:13:22.857408Z","iopub.execute_input":"2023-09-18T22:13:22.858218Z","iopub.status.idle":"2023-09-18T22:13:22.871785Z","shell.execute_reply.started":"2023-09-18T22:13:22.858181Z","shell.execute_reply":"2023-09-18T22:13:22.870591Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#import os\ndirectory_path = \"/kaggle/working/augmented_dataset\"\nos.makedirs(directory_path)\ndirectory_path = \"/kaggle/working/augmented_dataset/train\"\nos.makedirs(directory_path)\ndirectory_path = \"/kaggle/working/augmented_dataset/train/Closed\"\nos.makedirs(directory_path)\ndirectory_path = \"/kaggle/working/augmented_dataset/train/Open\"\nos.makedirs(directory_path)\ndirectory_path = \"/kaggle/working/augmented_dataset/train/no_yawn\"\nos.makedirs(directory_path)\ndirectory_path = \"/kaggle/working/augmented_dataset/train/yawn\"\nos.makedirs(directory_path)","metadata":{"execution":{"iopub.status.busy":"2023-09-18T22:13:22.875222Z","iopub.execute_input":"2023-09-18T22:13:22.875684Z","iopub.status.idle":"2023-09-18T22:13:22.883619Z","shell.execute_reply.started":"2023-09-18T22:13:22.875642Z","shell.execute_reply":"2023-09-18T22:13:22.882215Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Closed \n# Define your dataset directory and other parameters\ndataset_dir = '/kaggle/input/drowsiness-dataset/train/Closed'\noutput_dir = '/kaggle/working/augmented_dataset/train/Closed'\naugmentation_factor = 5  # Adjust this to determine how much you want to augment your dataset\n\n# Create an ImageDataGenerator with augmentation settings\ndatagen = ImageDataGenerator(\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\n\n# Load and augment images from the dataset\nfor root, _, files in os.walk(dataset_dir):\n    for filename in files:\n        if filename.endswith(('.jpg', '.jpeg', '.png', '.bmp')):  # Adjust extensions as needed\n            img = load_img(os.path.join(root, filename))\n            x = img_to_array(img)\n            x = np.expand_dims(x, axis=0)\n            \n            i = 0\n            for batch in datagen.flow(x, batch_size=1):\n                augmented_image = array_to_img(batch[0])\n                augmented_image.save(os.path.join(output_dir, f'augmented_{i}_{filename}'))\n                i += 1\n                if i >= augmentation_factor:\n                    break\n\nprint(f'Dataset augmentation complete.For Closed. Augmented {augmentation_factor} times.')\n","metadata":{"execution":{"iopub.status.busy":"2023-09-18T22:13:22.886022Z","iopub.execute_input":"2023-09-18T22:13:22.886464Z","iopub.status.idle":"2023-09-18T22:16:25.549946Z","shell.execute_reply.started":"2023-09-18T22:13:22.886428Z","shell.execute_reply":"2023-09-18T22:16:25.548973Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Dataset augmentation complete.For Closed. Augmented 5 times.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Open\n# Define your dataset directory and other parameters\ndataset_dir = '/kaggle/input/drowsiness-dataset/train/Open'\noutput_dir = '/kaggle/working/augmented_dataset/train/Open'\naugmentation_factor = 5  # Adjust this to determine how much you want to augment your dataset\n\n# Create an ImageDataGenerator with augmentation settings\ndatagen = ImageDataGenerator(\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\n\n# Load and augment images from the dataset\nfor root, _, files in os.walk(dataset_dir):\n    for filename in files:\n        if filename.endswith(('.jpg', '.jpeg', '.png', '.bmp')):  # Adjust extensions as needed\n            img = load_img(os.path.join(root, filename))\n            x = img_to_array(img)\n            x = np.expand_dims(x, axis=0)\n            \n            i = 0\n            for batch in datagen.flow(x, batch_size=1):\n                augmented_image = array_to_img(batch[0])\n                augmented_image.save(os.path.join(output_dir, f'augmented_{i}_{filename}'))\n                i += 1\n                if i >= augmentation_factor:\n                    break\n\nprint(f'Dataset augmentation complete. For Open. Augmented {augmentation_factor} times.')\n","metadata":{"execution":{"iopub.status.busy":"2023-09-18T22:16:25.551326Z","iopub.execute_input":"2023-09-18T22:16:25.551776Z","iopub.status.idle":"2023-09-18T22:19:00.316648Z","shell.execute_reply.started":"2023-09-18T22:16:25.551739Z","shell.execute_reply":"2023-09-18T22:19:00.314544Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Dataset augmentation complete. For Open. Augmented 5 times.\n","output_type":"stream"}]},{"cell_type":"code","source":"# no_yawn\n# Define your dataset directory and other parameters\ndataset_dir = '/kaggle/input/drowsiness-dataset/train/no_yawn'\noutput_dir = '/kaggle/working/augmented_dataset/train/no_yawn'\naugmentation_factor = 5  # Adjust this to determine how much you want to augment your dataset\n\n# Create an ImageDataGenerator with augmentation settings\ndatagen = ImageDataGenerator(\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\n\n# Load and augment images from the dataset\nfor root, _, files in os.walk(dataset_dir):\n    for filename in files:\n        if filename.endswith(('.jpg', '.jpeg', '.png', '.bmp')):  # Adjust extensions as needed\n            img = load_img(os.path.join(root, filename))\n            x = img_to_array(img)\n            x = np.expand_dims(x, axis=0)\n            \n            i = 0\n            for batch in datagen.flow(x, batch_size=1):\n                augmented_image = array_to_img(batch[0])\n                augmented_image.save(os.path.join(output_dir, f'augmented_{i}_{filename}'))\n                i += 1\n                if i >= augmentation_factor:\n                    break\n\nprint(f'Dataset augmentation complete. For no_yawn. Augmented {augmentation_factor} times.')\n","metadata":{"execution":{"iopub.status.busy":"2023-09-18T22:19:00.318058Z","iopub.execute_input":"2023-09-18T22:19:00.318479Z","iopub.status.idle":"2023-09-18T22:24:22.814708Z","shell.execute_reply.started":"2023-09-18T22:19:00.318443Z","shell.execute_reply":"2023-09-18T22:24:22.813741Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Dataset augmentation complete. For no_yawn. Augmented 5 times.\n","output_type":"stream"}]},{"cell_type":"code","source":"# yawn\n# Define your dataset directory and other parameters\ndataset_dir = '/kaggle/input/drowsiness-dataset/train/yawn'\noutput_dir = '/kaggle/working/augmented_dataset/train/yawn'\naugmentation_factor = 5  # Adjust this to determine how much you want to augment your dataset\n\n# Create an ImageDataGenerator with augmentation settings\ndatagen = ImageDataGenerator(\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\n\n# Load and augment images from the dataset\nfor root, _, files in os.walk(dataset_dir):\n    for filename in files:\n        if filename.endswith(('.jpg', '.jpeg', '.png', '.bmp')):  # Adjust extensions as needed\n            img = load_img(os.path.join(root, filename))\n            x = img_to_array(img)\n            x = np.expand_dims(x, axis=0)\n            \n            i = 0\n            for batch in datagen.flow(x, batch_size=1):\n                augmented_image = array_to_img(batch[0])\n                augmented_image.save(os.path.join(output_dir, f'augmented_{i}_{filename}'))\n                i += 1\n                if i >= augmentation_factor:\n                    break\n\nprint(f'Dataset augmentation complete. For yawn. Augmented {augmentation_factor} times.')\n","metadata":{"execution":{"iopub.status.busy":"2023-09-18T22:24:22.816639Z","iopub.execute_input":"2023-09-18T22:24:22.817612Z","iopub.status.idle":"2023-09-18T22:29:45.357092Z","shell.execute_reply.started":"2023-09-18T22:24:22.817577Z","shell.execute_reply":"2023-09-18T22:29:45.356038Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Dataset augmentation complete. For yawn. Augmented 5 times.\n","output_type":"stream"}]},{"cell_type":"code","source":"import shutil\n\n# Directory you want to zip\ndirectory_to_zip = \"/kaggle/working/augmented_dataset\"\n\n# Name for the resulting zip file\nzip_filename = \"/kaggle/working/augmented_dataset.zip\"\n\n# Create a zip archive of the directory\nshutil.make_archive(zip_filename[:-4], 'zip', directory_to_zip)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-18T22:29:45.358498Z","iopub.execute_input":"2023-09-18T22:29:45.361460Z","iopub.status.idle":"2023-09-18T22:30:00.397506Z","shell.execute_reply.started":"2023-09-18T22:29:45.361420Z","shell.execute_reply":"2023-09-18T22:30:00.396512Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/augmented_dataset.zip'"},"metadata":{}}]},{"cell_type":"code","source":"!mkdir -p /root/.kaggle\n!mv kaggle.json /root/.kaggle/\n","metadata":{"execution":{"iopub.status.busy":"2023-09-18T22:35:53.724315Z","iopub.execute_input":"2023-09-18T22:35:53.724697Z","iopub.status.idle":"2023-09-18T22:35:55.687740Z","shell.execute_reply.started":"2023-09-18T22:35:53.724665Z","shell.execute_reply":"2023-09-18T22:35:55.686506Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"mv: cannot stat 'kaggle.json': No such file or directory\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\n\nos.environ['KAGGLE_USERNAME'] = \"mmarifbakhtiar\"\nos.environ['KAGGLE_KEY'] = \"38982c08010bb2fd5a12f481feb91ee4\"\n","metadata":{"execution":{"iopub.status.busy":"2023-09-18T22:43:31.701329Z","iopub.execute_input":"2023-09-18T22:43:31.701760Z","iopub.status.idle":"2023-09-18T22:43:31.706918Z","shell.execute_reply.started":"2023-09-18T22:43:31.701728Z","shell.execute_reply":"2023-09-18T22:43:31.705457Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"from kaggle.api.kaggle_api_extended import KaggleApi\n\n# Initialize the Kaggle API client\napi = KaggleApi()\n\n# Authenticate without specifying the API token\napi.authenticate()\nUpload the zip file as a Kaggle dataset\napi.dataset_create_version(\"mmarifbakhtiar/augmented_dataset\", path=zip_filename, version_notes=\"Initial version\")\n\n# Get the download URL for the dataset\ndownload_url = api.dataset_download_url(\"mmarifbakhtiar/augmented_dataset\", version=\"1\")\n\n# Download the zip file to your local machine\napi.dataset_download_files(download_url, path=\"I:\\4-2 Fourth year Even\\Thesis book\", unzip=True)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-18T22:43:52.780945Z","iopub.execute_input":"2023-09-18T22:43:52.781319Z","iopub.status.idle":"2023-09-18T22:43:52.789669Z","shell.execute_reply.started":"2023-09-18T22:43:52.781290Z","shell.execute_reply":"2023-09-18T22:43:52.788289Z"},"trusted":true},"execution_count":17,"outputs":[{"traceback":["\u001b[0;36m  Cell \u001b[0;32mIn[17], line 8\u001b[0;36m\u001b[0m\n\u001b[0;31m    Upload the zip file as a Kaggle dataset\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"],"ename":"SyntaxError","evalue":"invalid syntax (1868234360.py, line 8)","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-09-18T22:36:00.540215Z","iopub.execute_input":"2023-09-18T22:36:00.540610Z","iopub.status.idle":"2023-09-18T22:36:00.606296Z","shell.execute_reply.started":"2023-09-18T22:36:00.540579Z","shell.execute_reply":"2023-09-18T22:36:00.604746Z"},"trusted":true},"execution_count":12,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[12], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Initialize the Kaggle API client (you need to have a Kaggle API token set up)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m api \u001b[38;5;241m=\u001b[39m KaggleApi()\n\u001b[0;32m---> 10\u001b[0m \u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauthenticate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m38982c08010bb2fd5a12f481feb91ee4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Upload the zip file as a Kaggle dataset\u001b[39;00m\n\u001b[1;32m     13\u001b[0m api\u001b[38;5;241m.\u001b[39mdataset_create_version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmmarifbakhtiar/augmented_dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, path\u001b[38;5;241m=\u001b[39mzip_filename, version_notes\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitial version\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mTypeError\u001b[0m: KaggleApi.authenticate() got an unexpected keyword argument 'api_token'"],"ename":"TypeError","evalue":"KaggleApi.authenticate() got an unexpected keyword argument 'api_token'","output_type":"error"}]}]}